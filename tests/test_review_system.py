# -*- coding: utf-8 -*-
"""
Test del sistema de revisi√≥n LLM
Verifica que el bucle de mejora funcione correctamente
"""

import os
import sys
import django

# Setup Django
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'config.settings')
django.setup()

from apps.chat.response_reviewer import ResponseReviewer
from apps.authentication.models import User


def test_reviewer_initialization():
    """Test 1: Verificar que ResponseReviewer se puede inicializar"""
    print("\n" + "="*80)
    print("TEST 1: Inicializaci√≥n de ResponseReviewer")
    print("="*80)

    try:
        # Obtener un usuario con API key configurada
        user = User.objects.filter(llm_api_key__isnull=False).first()

        if not user:
            print("[FAIL] No hay usuarios con API key configurada")
            return False

        print(f"[OK] Usuario encontrado: {user.email}")
        print(f"[OK] Proveedor: {user.llm_provider}")

        # Crear un LLM mock para testing
        from langchain_google_genai import ChatGoogleGenerativeAI

        if user.llm_provider == 'google':
            llm = ChatGoogleGenerativeAI(
                model='gemini-2.0-flash-exp',
                google_api_key=user.llm_api_key,
                temperature=0.3
            )
        else:
            print(f"‚ö†Ô∏è Proveedor {user.llm_provider} no soportado en este test, usando Gemini por defecto")
            # Aqu√≠ podr√≠as a√±adir soporte para otros providers
            return False

        # Crear reviewer
        reviewer = ResponseReviewer(llm)
        print(f"‚úì ResponseReviewer creado correctamente")

        return True

    except Exception as e:
        print(f"‚ùå Error en inicializaci√≥n: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_review_response():
    """Test 2: Verificar que review_response funciona con una respuesta real"""
    print("\n" + "="*80)
    print("TEST 2: Revisi√≥n de una respuesta de prueba")
    print("="*80)

    try:
        # Obtener usuario
        user = User.objects.filter(llm_api_key__isnull=False, llm_provider='google').first()

        if not user:
            print("‚ùå No hay usuarios con Gemini configurado")
            return False

        # Crear LLM
        from langchain_google_genai import ChatGoogleGenerativeAI
        llm = ChatGoogleGenerativeAI(
            model='gemini-2.0-flash-exp',
            google_api_key=user.llm_api_key,
            temperature=0.3
        )

        # Crear reviewer
        reviewer = ResponseReviewer(llm)

        # Respuesta de prueba (MAL FORMATEADA - deber√≠a detectar problemas)
        bad_response = """Aqu√≠ est√°n las licitaciones que encontr√©:

1. Licitaci√≥n de servicios inform√°ticos - Presupuesto: 500000 EUR
2. Licitaci√≥n de mantenimiento de software - Presupuesto: 250000 EUR
3. Licitaci√≥n de desarrollo web - Presupuesto: 100000 EUR

Estas son las que m√°s te pueden interesar."""

        # Metadata de prueba
        metadata = {
            'documents_used': [
                {'id': '00668461-2025', 'section': 'title'},
                {'id': '00668462-2025', 'section': 'description'}
            ],
            'tools_used': ['search_by_cpv'],
            'route': 'vectorstore'
        }

        # Ejecutar revisi√≥n
        print("\n[REVIEWER] Llamando a review_response()...")
        review_result = reviewer.review_response(
            user_question="Dame las mejores licitaciones para desarrollo de software",
            conversation_history=[],
            initial_response=bad_response,
            metadata=metadata
        )

        print(f"\n[RESULTADO]")
        print(f"Status: {review_result['status']}")
        print(f"Score: {review_result['score']}/100")
        print(f"\nIssues ({len(review_result['issues'])}):")
        for issue in review_result['issues']:
            print(f"  - {issue}")
        print(f"\nSuggestions ({len(review_result['suggestions'])}):")
        for suggestion in review_result['suggestions']:
            print(f"  - {suggestion}")

        if review_result['feedback']:
            print(f"\nFeedback:")
            print(f"  {review_result['feedback']}")

        # Verificar que detect√≥ problemas (deber√≠a tener NEEDS_IMPROVEMENT)
        if review_result['status'] == 'NEEDS_IMPROVEMENT':
            print(f"\n‚úì Revisor detect√≥ problemas correctamente")
            return True
        else:
            print(f"\n‚ö†Ô∏è Revisor aprob√≥ una respuesta con formato incorrecto (esper√°bamos NEEDS_IMPROVEMENT)")
            return False

    except Exception as e:
        print(f"‚ùå Error en revisi√≥n: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_good_response():
    """Test 3: Verificar que una respuesta bien formateada se aprueba"""
    print("\n" + "="*80)
    print("TEST 3: Revisi√≥n de una respuesta CORRECTA")
    print("="*80)

    try:
        # Obtener usuario
        user = User.objects.filter(llm_api_key__isnull=False, llm_provider='google').first()

        if not user:
            print("‚ùå No hay usuarios con Gemini configurado")
            return False

        # Crear LLM
        from langchain_google_genai import ChatGoogleGenerativeAI
        llm = ChatGoogleGenerativeAI(
            model='gemini-2.0-flash-exp',
            google_api_key=user.llm_api_key,
            temperature=0.3
        )

        # Crear reviewer
        reviewer = ResponseReviewer(llm)

        # Respuesta de prueba (BIEN FORMATEADA)
        good_response = """Bas√°ndome en tu perfil y las licitaciones disponibles, te recomiendo:

## Servicios inform√°ticos para SAP - ID: 00668461-2025

**Por qu√© es la m√°s adecuada:**
- El presupuesto de 500.000 EUR es ideal para empresas de tu tama√±o
- Tu experiencia en desarrollo de software coincide con el CPV 72267100
- Plazo de 45 d√≠as, lo que te da tiempo suficiente para preparar una propuesta s√≥lida

**An√°lisis de fit:**
- **Presupuesto:** 500.000 EUR - Adecuado para tu capacidad financiera actual
- **Plazo:** 15/03/2025 - Holgado, permite preparaci√≥n detallada
- **Coincidencia con perfil:** 95% (CPV match + sector tecnolog√≠a)

**Datos clave:**
- **Organismo:** Ministerio de Econom√≠a
- **CPV:** 72267100 - Servicios de software empresarial
- **Presupuesto:** 500.000 EUR
- **Plazo l√≠mite:** 15 de marzo de 2025
- **Tipo contrato:** Servicios

[ID: 00668461-2025 | title]"""

        # Metadata de prueba
        metadata = {
            'documents_used': [
                {'id': '00668461-2025', 'section': 'title'}
            ],
            'tools_used': ['get_company_info', 'search_by_cpv'],
            'route': 'vectorstore'
        }

        # Ejecutar revisi√≥n
        print("\n[REVIEWER] Llamando a review_response()...")
        review_result = reviewer.review_response(
            user_question="Dame la mejor licitaci√≥n para mi empresa",
            conversation_history=[],
            initial_response=good_response,
            metadata=metadata
        )

        print(f"\n[RESULTADO]")
        print(f"Status: {review_result['status']}")
        print(f"Score: {review_result['score']}/100")

        # Verificar que aprob√≥ la respuesta
        if review_result['status'] == 'APPROVED':
            print(f"\n‚úì Revisor aprob√≥ respuesta bien formateada correctamente")
            return True
        else:
            print(f"\n‚ö†Ô∏è Revisor rechaz√≥ una respuesta correcta (esper√°bamos APPROVED)")
            print(f"Issues: {review_result['issues']}")
            return False

    except Exception as e:
        print(f"‚ùå Error en revisi√≥n: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """Ejecutar todos los tests"""
    print("\n" + "="*80)
    print("TESTING SISTEMA DE REVISI√ìN LLM")
    print("="*80)

    results = []

    # Test 1: Inicializaci√≥n
    results.append(("Inicializaci√≥n", test_reviewer_initialization()))

    # Test 2: Revisi√≥n de respuesta mala
    results.append(("Revisi√≥n respuesta mala", test_review_response()))

    # Test 3: Revisi√≥n de respuesta buena
    results.append(("Revisi√≥n respuesta buena", test_good_response()))

    # Resumen
    print("\n" + "="*80)
    print("RESUMEN DE TESTS")
    print("="*80)

    passed = sum(1 for _, result in results if result)
    total = len(results)

    for test_name, result in results:
        status = "‚úì PASS" if result else "‚úó FAIL"
        print(f"{status} - {test_name}")

    print(f"\nTotal: {passed}/{total} tests pasados")

    if passed == total:
        print("\nüéâ TODOS LOS TESTS PASARON!")
    else:
        print(f"\n‚ö†Ô∏è {total - passed} tests fallaron")

    return passed == total


if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)
