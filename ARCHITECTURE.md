# üèóÔ∏è Arquitectura del Sistema TenderAI v3.0

**Sistema de Function Calling Multi-Proveedor para An√°lisis de Licitaciones**

---

## üìã √çndice

1. [Visi√≥n General](#visi√≥n-general)
2. [Arquitectura de Alto Nivel](#arquitectura-de-alto-nivel)
3. [Componentes Principales](#componentes-principales)
4. [Flujo de Datos](#flujo-de-datos)
5. [Proveedores LLM](#proveedores-llm)
6. [Sistema de Tools](#sistema-de-tools)
7. [Base de Datos](#base-de-datos)

---

## üéØ Visi√≥n General

TenderAI es una plataforma Django que utiliza **Function Calling** para permitir que los LLMs interact√∫en din√°micamente con datos de licitaciones p√∫blicas mediante **9 tools especializadas**.

### Caracter√≠sticas Clave

- ‚úÖ **3 proveedores LLM**: Ollama (local), OpenAI, Google Gemini
- ‚úÖ **9 tools especializadas**: B√∫squeda, filtrado, an√°lisis, comparaci√≥n
- ‚úÖ **Decisi√≥n autom√°tica**: LLM decide qu√© tools usar y cu√°ndo
- ‚úÖ **Iteraci√≥n inteligente**: Hasta 5 pasos para consultas complejas
- ‚úÖ **ChromaDB**: B√∫squeda vectorial sem√°ntica
- ‚úÖ **Django ORM**: Consultas SQL eficientes

---

## üèõÔ∏è Arquitectura de Alto Nivel

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        FRONTEND (Browser)                         ‚îÇ
‚îÇ                     Bootstrap 5 + JavaScript                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ HTTP/AJAX
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      DJANGO APPLICATION                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                      chat/views.py                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              (ChatMessageCreateView)                       ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                  chat/services.py                          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                 (ChatAgentService)                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Detecta proveedor del usuario                          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Crea FunctionCallingAgent                              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Maneja historial de conversaci√≥n                       ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚Üì                                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   AGENT_IA_CORE         ‚îÇ     ‚îÇ   DJANGO ORM            ‚îÇ
‚îÇ                         ‚îÇ     ‚îÇ                         ‚îÇ
‚îÇ  FunctionCallingAgent   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ  Tender Model           ‚îÇ
‚îÇ  ToolRegistry           ‚îÇ     ‚îÇ  CompanyProfile         ‚îÇ
‚îÇ  9 Tools                ‚îÇ     ‚îÇ  ChatMessage            ‚îÇ
‚îÇ  SchemaConverter        ‚îÇ     ‚îÇ  User                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ
            ‚îú‚îÄ‚îÄ‚Üí Ollama (localhost:11434)
            ‚îú‚îÄ‚îÄ‚Üí OpenAI API
            ‚îî‚îÄ‚îÄ‚Üí Google Gemini API
```

---

## üß© Componentes Principales

### 1. FunctionCallingAgent

**Ubicaci√≥n**: `agent_ia_core/agent_function_calling.py`

**Responsabilidades**:
- Coordinar la ejecuci√≥n de tools
- Gestionar iteraciones (m√°ximo 5)
- Comunicarse con diferentes proveedores LLM
- Mantener historial de conversaci√≥n

**M√©todos clave**:
```python
class FunctionCallingAgent:
    def __init__(self, llm_provider, llm_model, llm_api_key, retriever):
        # Inicializa LLM seg√∫n proveedor
        self.llm = self._create_llm()
        self.tool_registry = ToolRegistry(retriever, db_session)

    def query(self, question, conversation_history):
        # Loop de function calling (m√°x 5 iteraciones)
        # 1. LLM decide tools
        # 2. Ejecutar tools
        # 3. LLM procesa resultados
        # 4. Repetir o retornar respuesta

    def _call_ollama_with_tools(self, messages):
        # Llamada nativa a Ollama con tools

    def _call_openai_with_tools(self, messages):
        # Llamada a OpenAI via LangChain

    def _call_gemini_with_tools(self, messages):
        # Llamada a Gemini via LangChain
```

### 2. ToolRegistry

**Ubicaci√≥n**: `agent_ia_core/tools/registry.py`

**Responsabilidades**:
- Registrar las 9 tools disponibles
- Convertir schemas al formato del proveedor
- Ejecutar tool calls

**M√©todos clave**:
```python
class ToolRegistry:
    def __init__(self, retriever, db_session):
        self.tools = {}
        self._register_all_tools()

    def get_ollama_tools(self):
        # Schemas en formato Ollama

    def get_openai_tools(self):
        # Schemas en formato OpenAI

    def get_gemini_tools(self):
        # Schemas en formato Gemini

    def execute_tool_calls(self, tool_calls):
        # Ejecuta m√∫ltiples tools en paralelo
```

### 3. Tools (9 especializadas)

**Ubicaci√≥n**: `agent_ia_core/tools/`

**B√∫squeda** (`search_tools.py`):
1. **SearchTendersTool**: B√∫squeda vectorial con ChromaDB
2. **FindByBudgetTool**: Filtrado por presupuesto (Django ORM)
3. **FindByDeadlineTool**: Filtrado por fecha l√≠mite
4. **FindByCPVTool**: Filtrado por sector (ChromaDB)
5. **FindByLocationTool**: Filtrado geogr√°fico (ChromaDB)

**Informaci√≥n** (`tender_tools.py`):
6. **GetTenderDetailsTool**: Detalles completos (Django ORM)
7. **GetTenderXMLTool**: Obtener XML completo (FileSystem)

**An√°lisis** (`search_tools.py` y `tender_tools.py`):
8. **GetStatisticsTool**: Estad√≠sticas agregadas (Django Aggregate)
9. **CompareTendersTool**: Comparaci√≥n lado a lado

**Cada tool implementa**:
```python
class BaseTool(ABC):
    name: str
    description: str

    @abstractmethod
    def run(self, **kwargs) -> Dict[str, Any]:
        # L√≥gica de ejecuci√≥n

    @abstractmethod
    def get_schema(self) -> Dict[str, Any]:
        # Schema en formato JSON Schema
```

### 4. SchemaConverter

**Ubicaci√≥n**: `agent_ia_core/tools/schema_converters.py`

**Responsabilidad**: Convertir schemas entre formatos de proveedores

**Conversiones soportadas**:
- **Ollama**: Formato OpenAI compatible
- **OpenAI**: Formato est√°ndar OpenAI Function Calling
- **Gemini**: Tipos en MAY√öSCULAS (STRING, INTEGER, etc.)

```python
class SchemaConverter:
    @staticmethod
    def to_openai_format(base_schema):
        # JSON Schema ‚Üí OpenAI format

    @staticmethod
    def to_gemini_format(base_schema):
        # JSON Schema ‚Üí Gemini format (tipos en MAY√öSCULAS)

    @staticmethod
    def to_ollama_format(base_schema):
        # JSON Schema ‚Üí Ollama format
```

### 5. ChatAgentService

**Ubicaci√≥n**: `chat/services.py`

**Responsabilidad**: Integraci√≥n entre Django y agent_ia_core

```python
class ChatAgentService:
    def __init__(self, user, use_function_calling=None):
        self.user = user
        self.provider = user.llm_provider  # 'ollama', 'openai', 'google'
        self.use_function_calling = use_function_calling

    def _create_function_calling_agent(self):
        # Crear retriever
        retriever = create_retriever(provider=self.provider)

        # Determinar modelo seg√∫n proveedor
        if self.provider == 'ollama':
            model = user.ollama_model
        elif self.provider == 'openai':
            model = 'gpt-4o-mini'
        elif self.provider == 'google':
            model = 'gemini-2.0-flash-exp'

        # Crear agente
        agent = FunctionCallingAgent(
            llm_provider=self.provider,
            llm_model=model,
            llm_api_key=api_key,
            retriever=retriever
        )
        return agent

    def query(self, question, conversation_history):
        agent = self._get_agent()
        return agent.query(question, conversation_history)
```

### 6. Retriever (ChromaDB)

**Ubicaci√≥n**: `agent_ia_core/retriever.py`

**Responsabilidad**: B√∫squeda vectorial sem√°ntica

```python
class HybridRetriever:
    def __init__(self, provider, api_key, embedding_model, k):
        self.embeddings = self._create_embeddings(provider, api_key, embedding_model)
        self.vectorstore = Chroma(
            collection_name="eforms_chunks",
            embedding_function=self.embeddings,
            persist_directory="data/index/chroma"
        )

    def retrieve(self, query, filters=None, k=None):
        # B√∫squeda por similitud con filtros opcionales
        results = self.vectorstore.similarity_search_with_score(
            query, k=k, filter=filters
        )
        return self._format_results(results)
```

---

## üîÑ Flujo de Datos

### Flujo Completo: Usuario hace pregunta

```
1. FRONTEND
   Usuario escribe: "Busca licitaciones de IT con presupuesto > 50k"
   ‚Üí JavaScript env√≠a AJAX POST a /chat/<session_id>/message/

2. DJANGO VIEWS
   ChatMessageCreateView recibe request
   ‚Üí Guarda mensaje del usuario en DB
   ‚Üí Llama a ChatAgentService.query()

3. CHATAGENTSERVICE
   ‚Üí Lee proveedor del usuario (ollama/openai/google)
   ‚Üí Crea o reutiliza FunctionCallingAgent
   ‚Üí Convierte historial a formato est√°ndar
   ‚Üí Llama a agent.query(question, history)

4. FUNCTIONCALLINGAGENT
   ITERACI√ìN 1:
   ‚Üí Prepara mensajes para LLM
   ‚Üí Obtiene tools en formato del proveedor (via ToolRegistry)
   ‚Üí Llama a _call_ollama_with_tools() / _call_openai_with_tools() / etc.

   LLM RESPONDE:
   ‚Üí "Voy a usar find_by_cpv('IT') y find_by_budget(min_budget=50000)"

   ‚Üí ToolRegistry.execute_tool_calls([
       {function: {name: 'find_by_cpv', arguments: {cpv_code: '72'}}},
       {function: {name: 'find_by_budget', arguments: {min_budget: 50000}}}
     ])

5. TOOLREGISTRY
   ‚Üí Obtiene tools: find_by_cpv, find_by_budget
   ‚Üí Ejecuta ambas en paralelo

   find_by_cpv:
   ‚Üí Usa HybridRetriever (ChromaDB)
   ‚Üí Filtra por CPV = 72
   ‚Üí Retorna 10 licitaciones

   find_by_budget:
   ‚Üí Usa Django ORM: Tender.objects.filter(budget_amount__gte=50000)
   ‚Üí Retorna 8 licitaciones

   ‚Üí Retorna resultados a FunctionCallingAgent

6. FUNCTIONCALLINGAGENT
   ITERACI√ìN 2:
   ‚Üí A√±ade resultados al historial
   ‚Üí Vuelve a llamar al LLM con los datos

   LLM GENERA RESPUESTA FINAL:
   ‚Üí "Encontr√© 3 licitaciones de IT con presupuesto mayor a 50,000 EUR:
      1. Desarrollo ERP - 150,000 EUR
      2. Migraci√≥n cloud - 85,000 EUR
      3. Consultor√≠a IT - 65,000 EUR"

   ‚Üí No hay tool_calls, es respuesta final
   ‚Üí Retorna respuesta a ChatAgentService

7. CHATAGENTSERVICE
   ‚Üí Recibe respuesta
   ‚Üí Extrae documentos usados
   ‚Üí Retorna a Django Views

8. DJANGO VIEWS
   ‚Üí Guarda respuesta del asistente en DB
   ‚Üí Retorna JSON a frontend

9. FRONTEND
   ‚Üí JavaScript recibe JSON
   ‚Üí Renderiza mensaje del asistente
   ‚Üí Muestra metadata (tools usadas, iteraciones)
```

---

## ü§ñ Proveedores LLM

### Ollama (Local)

**Comunicaci√≥n**:
```python
import ollama

response = ollama.chat(
    model='qwen2.5:7b',
    messages=messages,
    tools=tool_registry.get_ollama_tools()
)

tool_calls = response['message'].get('tool_calls', [])
```

**Ventajas**:
- üÜì Gratis
- üîí 100% local (privacidad)
- ‚ö° R√°pido (sin latencia de red)

**Desventajas**:
- üíª Requiere recursos (16GB+ RAM)
- üéØ Calidad depende del modelo local

### OpenAI (Cloud)

**Comunicaci√≥n**:
```python
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage

llm = ChatOpenAI(model='gpt-4o-mini', api_key=api_key)
llm_with_tools = llm.bind_tools(tool_registry.get_openai_tools())
response = llm_with_tools.invoke(messages)

tool_calls = response.tool_calls
```

**Ventajas**:
- üéØ Alta calidad
- ‚ö° R√°pido
- üìä Mejores resultados en consultas complejas

**Desventajas**:
- üí∞ Costo por token
- ‚òÅÔ∏è Datos en cloud (privacidad)
- üåê Requiere internet

### Google Gemini (Cloud)

**Comunicaci√≥n**:
```python
from langchain_google_genai import ChatGoogleGenerativeAI

llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash-exp', api_key=api_key)
llm_with_tools = llm.bind_tools(tool_registry.get_gemini_tools())
response = llm_with_tools.invoke(messages)

tool_calls = response.tool_calls
```

**Ventajas**:
- üí∞ M√°s econ√≥mico que OpenAI
- ‚ö° Muy r√°pido
- üéØ Buena calidad

**Desventajas**:
- üí∞ Costo por token (menor que OpenAI)
- ‚òÅÔ∏è Datos en cloud
- üåê Requiere internet

---

## üõ†Ô∏è Sistema de Tools

### Categor√≠as

#### üîç B√∫squeda (5 tools)

**Usan ChromaDB** (vectorial):
- `search_tenders`: B√∫squeda sem√°ntica general
- `find_by_cpv`: Filtrado por sector (CPV codes)
- `find_by_location`: Filtrado geogr√°fico (NUTS codes)

**Usan Django ORM** (SQL):
- `find_by_budget`: Filtrado por presupuesto
- `find_by_deadline`: Filtrado por fecha l√≠mite

#### üìÑ Informaci√≥n (2 tools)

**Usan Django ORM**:
- `get_tender_details`: Detalles completos de una licitaci√≥n
- `get_tender_xml`: Obtener XML completo del filesystem

#### üìä An√°lisis (2 tools)

**Usan Django ORM + Aggregates**:
- `get_statistics`: Estad√≠sticas agregadas (Count, Avg, Sum, Min, Max)
- `compare_tenders`: Comparaci√≥n lado a lado de 2-5 licitaciones

### Decisi√≥n del LLM

El LLM decide autom√°ticamente qu√© tools usar seg√∫n la query:

| Query | Tools Usadas | Raz√≥n |
|-------|-------------|-------|
| "Busca licitaciones de IT" | `search_tenders` + `find_by_cpv` | B√∫squeda sem√°ntica + filtro por sector |
| "Licitaciones > 50k euros" | `find_by_budget` | Filtro directo por presupuesto |
| "Estad√≠sticas generales" | `get_statistics` | An√°lisis agregado |
| "Compara X e Y" | `get_tender_details` (x2) + `compare_tenders` | Obtiene detalles y compara |

---

## üíæ Base de Datos

### Modelos Django

#### User (authentication/models.py)
```python
class User(AbstractUser):
    email = EmailField(unique=True)
    llm_provider = CharField(max_length=50)  # 'ollama', 'openai', 'google'
    llm_api_key = TextField(blank=True)
    ollama_model = CharField(max_length=100)
    use_function_calling = BooleanField(default=False)
```

#### Tender (tenders/models.py)
```python
class Tender(Model):
    ojs_notice_id = CharField(max_length=255, unique=True)
    title = TextField()
    description = TextField(blank=True)
    buyer_name = CharField(max_length=500)
    budget_amount = DecimalField(max_digits=15, decimal_places=2, null=True)
    currency = CharField(max_length=3, null=True)
    tender_deadline_date = DateField(null=True)
    cpv_codes = JSONField(default=list)
    nuts_regions = JSONField(default=list)
    source_path = CharField(max_length=500, blank=True)  # Path al XML
    # ... m√°s campos
```

#### ChatSession (chat/models.py)
```python
class ChatSession(Model):
    user = ForeignKey(User, on_delete=CASCADE)
    title = CharField(max_length=200)
    created_at = DateTimeField(auto_now_add=True)
    updated_at = DateTimeField(auto_now=True)
    is_archived = BooleanField(default=False)
```

#### ChatMessage (chat/models.py)
```python
class ChatMessage(Model):
    session = ForeignKey(ChatSession, on_delete=CASCADE)
    role = CharField(max_length=20)  # 'user', 'assistant'
    content = TextField()
    timestamp = DateTimeField(auto_now_add=True)
    metadata = JSONField(default=dict, blank=True)  # tools_used, iterations, etc.
```

### ChromaDB

**Colecci√≥n**: `eforms_chunks`
**Documentos**: 235+ chunks de 37 licitaciones

**Metadata por documento**:
```python
{
    'ojs_notice_id': '123456-2024',
    'section': 'object_description',  # o 'cpv_codes', 'nuts_regions', etc.
    'title': 'Desarrollo de software',
    'buyer_name': 'Ministerio',
    'cpv_codes': ['72000000'],
    'nuts_regions': ['ES300'],
    'budget_amount': 150000.0,
    'tender_deadline_date': '2024-03-20'
}
```

**Filtros soportados**:
- `cpv_codes`: Lista de c√≥digos CPV
- `nuts_regions`: Lista de c√≥digos NUTS
- `budget_amount`: Rango de presupuesto
- `tender_deadline_date`: Rango de fechas

---

## üìä M√©tricas de Rendimiento

### Latencia Promedio

| Operaci√≥n | Ollama (local) | OpenAI (API) | Gemini (API) |
|-----------|----------------|--------------|--------------|
| **Tool simple** (search) | 150-300ms | 200-500ms | 150-400ms |
| **Tool compleja** (compare) | 300-600ms | 400-800ms | 300-700ms |
| **Iteraci√≥n completa** | 500-1000ms | 800-1500ms | 600-1200ms |
| **Query multi-tool** | 1-2s | 1.5-3s | 1-2.5s |

### Consumo de Recursos

| Proveedor | RAM | CPU | Disco | Red |
|-----------|-----|-----|-------|-----|
| **Ollama** | 8-16GB | Alto | 5-10GB (modelo) | No |
| **OpenAI** | < 500MB | Bajo | M√≠nimo | S√≠ |
| **Gemini** | < 500MB | Bajo | M√≠nimo | S√≠ |

---

## üîê Seguridad

### API Keys
- Almacenadas por usuario en DB (encriptadas en producci√≥n)
- No compartidas entre usuarios
- Validadas antes de cada llamada

### Datos
- Ollama: 100% local, nada sale de la m√°quina
- OpenAI/Gemini: Solo query y contexto necesario, no datos sensibles

### Rate Limiting
- Por usuario (no implementado a√∫n, roadmap)
- Por proveedor (l√≠mites de API)

---

## üîó Referencias

- **C√≥digo fuente**: `agent_ia_core/`
- **Tools**: [TOOLS_REFERENCE.md](TOOLS_REFERENCE.md)
- **Configuraci√≥n**: [CONFIGURACION_AGENTE.md](CONFIGURACION_AGENTE.md)
- **Changelog**: [CHANGELOG.md](CHANGELOG.md)

---

**ü§ñ Generated with [Claude Code](https://claude.com/claude-code)**

**Co-Authored-By: Claude <noreply@anthropic.com>**
