# ğŸ—ï¸ Arquitectura del Sistema TenderAI v3.7

**Sistema de Function Calling Multi-Proveedor con Review Loop AutomÃ¡tico**

---

## ğŸ“‹ Ãndice

1. [VisiÃ³n General](#visiÃ³n-general)
2. [Arquitectura de Alto Nivel](#arquitectura-de-alto-nivel)
3. [Componentes Principales](#componentes-principales)
4. [Sistema de Tools](#sistema-de-tools)
5. [Sistema de Review y Mejora](#sistema-de-review-y-mejora)
6. [Flujo de Datos Completo](#flujo-de-datos-completo)
7. [Proveedores LLM](#proveedores-llm)
8. [Base de Datos](#base-de-datos)

---

## ğŸ¯ VisiÃ³n General

TenderAI es una plataforma Django que utiliza **Function Calling** para permitir que los LLMs interactÃºen dinÃ¡micamente con datos de licitaciones pÃºblicas mediante **16 tools especializadas** y un **sistema de auto-mejora** con doble LLM.

### CaracterÃ­sticas Clave v3.7

- âœ… **3 proveedores LLM**: Ollama (local), OpenAI, Google Gemini
- âœ… **16 tools especializadas**: BÃºsqueda, anÃ¡lisis, web, navegaciÃ³n interactiva
- âœ… **Review Loop automÃ¡tico**: Segunda iteraciÃ³n SIEMPRE ejecutada
- âœ… **Navegador interactivo**: Playwright para sitios JavaScript
- âœ… **Web Search**: Google Custom Search API
- âœ… **Grading y Verification**: Filtrado inteligente de documentos
- âœ… **ChromaDB**: BÃºsqueda vectorial semÃ¡ntica
- âœ… **IteraciÃ³n inteligente**: Hasta 15 pasos para consultas complejas

---

## ğŸ›ï¸ Arquitectura de Alto Nivel

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FRONTEND (Browser)                         â”‚
â”‚                     Bootstrap 5 + JavaScript                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ HTTP/AJAX
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DJANGO APPLICATION                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                      chat/views.py                         â”‚  â”‚
â”‚  â”‚              (ChatMessageCreateView)                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                  chat/services.py                          â”‚  â”‚
â”‚  â”‚                 (ChatAgentService)                         â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  - Detecta proveedor del usuario                          â”‚  â”‚
â”‚  â”‚  - Crea FunctionCallingAgent                              â”‚  â”‚
â”‚  â”‚  - Ejecuta Review Loop (SIEMPRE)                          â”‚  â”‚
â”‚  â”‚  - Maneja historial conversacional                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚               chat/response_reviewer.py                    â”‚  â”‚
â”‚  â”‚                 (ResponseReviewer)                         â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  - Revisa formato (30%)                                   â”‚  â”‚
â”‚  â”‚  - Revisa contenido (40%)                                 â”‚  â”‚
â”‚  â”‚  - Revisa anÃ¡lisis (30%)                                  â”‚  â”‚
â”‚  â”‚  - Proporciona feedback especÃ­fico                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â†“                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AGENT_IA_CORE         â”‚     â”‚   DJANGO ORM            â”‚
â”‚                         â”‚     â”‚                         â”‚
â”‚  FunctionCallingAgent   â”‚â”€â”€â”€â”€â†’â”‚  Tender Model           â”‚
â”‚  ToolRegistry (16)      â”‚     â”‚  CompanyProfile         â”‚
â”‚  SchemaConverter        â”‚     â”‚  ChatMessage            â”‚
â”‚  ResponseReviewer LLM   â”‚     â”‚  User                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”œâ”€â”€â†’ Ollama (localhost:11434)
            â”œâ”€â”€â†’ OpenAI API
            â”œâ”€â”€â†’ Google Gemini API
            â”œâ”€â”€â†’ Google Custom Search API
            â””â”€â”€â†’ Playwright (Chromium)
```

---

## ğŸ§© Componentes Principales

### 1. FunctionCallingAgent

**UbicaciÃ³n**: `agent_ia_core/agent_function_calling.py`

**Responsabilidades**:
- Coordinar la ejecuciÃ³n de tools (16 disponibles)
- Gestionar iteraciones (mÃ¡ximo 15)
- Comunicarse con diferentes proveedores LLM
- Mantener historial conversacional

**MÃ©todos clave**:
```python
class FunctionCallingAgent:
    def __init__(self, llm_provider, llm_model, llm_api_key, retriever, db_session, user):
        # Inicializa LLM segÃºn proveedor
        self.llm = self._create_llm()
        self.tool_registry = ToolRegistry(retriever, db_session, user)
        self.max_iterations = 15

    def query(self, question, conversation_history):
        # Loop de function calling (mÃ¡x 15 iteraciones)
        # 1. LLM decide tools
        # 2. Ejecutar tools
        # 3. LLM procesa resultados
        # 4. Repetir o retornar respuesta
```

### 2. ToolRegistry

**UbicaciÃ³n**: `agent_ia_core/tools/registry.py`

**Responsabilidades**:
- Registrar las 16 tools disponibles
- Convertir schemas al formato del proveedor
- Ejecutar tool calls en paralelo
- Inyectar LLM a tools que lo necesitan

**Tools registradas**:
```python
# Tools de contexto (2)
- get_company_info: InformaciÃ³n de empresa del usuario
- get_tenders_summary: Resumen de licitaciones guardadas

# Tools de bÃºsqueda (5)
- search_tenders: BÃºsqueda vectorial ChromaDB
- find_by_budget: Filtrado por presupuesto
- find_by_deadline: Filtrado por fecha
- find_by_cpv: Filtrado por sector
- find_by_location: Filtrado geogrÃ¡fico

# Tools de informaciÃ³n (2)
- get_tender_details: Detalles completos
- get_tender_xml: XML original

# Tools de anÃ¡lisis (2)
- get_statistics: EstadÃ­sticas agregadas
- compare_tenders: ComparaciÃ³n lado a lado

# Tools opcionales (5)
- grade_documents: Filtrado inteligente (opcional)
- verify_fields: VerificaciÃ³n con XML (opcional)
- web_search: Google Custom Search (opcional)
- browse_webpage: ExtracciÃ³n web estÃ¡tica (opcional)
- browse_interactive: Navegador Playwright (opcional)
```

### 3. ResponseReviewer

**UbicaciÃ³n**: `chat/response_reviewer.py`

**Responsabilidades**:
- Revisar respuesta inicial del agente principal
- Evaluar formato, contenido y anÃ¡lisis
- Proporcionar feedback especÃ­fico y constructivo
- Generar score de calidad (0-100)

**Criterios de evaluaciÃ³n**:
```python
FORMATO (30 puntos):
- Â¿Usa Markdown correctamente?
- Â¿Headers ## para mÃºltiples licitaciones?
- Â¿Estructura clara y legible?

CONTENIDO (40 puntos):
- Â¿Responde completamente la pregunta?
- Â¿Incluye todos los datos relevantes?
- Â¿Falta informaciÃ³n importante?

ANÃLISIS (30 puntos):
- Â¿Justifica recomendaciones con datos?
- Â¿Usa documentos correctamente?
- Â¿Es Ãºtil y profesional?
```

**Proceso**:
1. Recibe respuesta inicial + metadata
2. Llama al LLM revisor con prompt especÃ­fico
3. Parsea resultado (status, score, issues, suggestions, feedback)
4. Retorna anÃ¡lisis estructurado

### 4. ChatAgentService (con Review Loop)

**UbicaciÃ³n**: `chat/services.py`

**Responsabilidad**: Orquestar el flujo completo con mejora automÃ¡tica

**Flujo actualizado**:
```python
class ChatAgentService:
    def process_message(self, message, conversation_history):
        # 1. Ejecutar query inicial
        result = agent.query(message, conversation_history)
        response_content = result['answer']

        # 2. REVIEW LOOP (SIEMPRE ejecutado)
        reviewer = ResponseReviewer(agent.llm)
        review_result = reviewer.review_response(
            user_question=message,
            conversation_history=conversation_history,
            initial_response=response_content,
            metadata=result
        )

        # 3. Segunda iteraciÃ³n de mejora (SIEMPRE)
        improvement_prompt = f"""Tu respuesta fue revisada.

        Respuesta original: {response_content}

        Problemas: {review_result['issues']}
        Sugerencias: {review_result['suggestions']}
        Feedback: {review_result['feedback']}

        Genera una respuesta MEJORADA con acceso completo a tools."""

        improved_result = agent.query(
            improvement_prompt,
            conversation_history + [
                {'role': 'user', 'content': message},
                {'role': 'assistant', 'content': response_content}
            ]
        )

        # 4. Merge resultados de ambas iteraciones
        final_response = improved_result['answer']
        final_documents = result['documents'] + improved_result['documents']

        return final_response, final_documents, review_metadata
```

### 5. Retriever (ChromaDB)

**UbicaciÃ³n**: `agent_ia_core/retriever.py`

**Responsabilidad**: BÃºsqueda vectorial semÃ¡ntica

```python
class HybridRetriever:
    def __init__(self, provider, api_key, embedding_model, k):
        self.embeddings = self._create_embeddings(provider, api_key, embedding_model)
        self.vectorstore = Chroma(
            collection_name="eforms_chunks",
            embedding_function=self.embeddings,
            persist_directory="data/index/chroma"
        )

    def retrieve(self, query, filters=None, k=None):
        results = self.vectorstore.similarity_search_with_score(
            query, k=k, filter=filters
        )
        return self._format_results(results)
```

---

## ğŸ› ï¸ Sistema de Tools

### CategorizaciÃ³n Completa (16 Tools)

#### ğŸ¢ Tools de Contexto (2)
**DescripciÃ³n**: InformaciÃ³n especÃ­fica del usuario

1. **get_company_info**: Perfil de empresa del usuario
2. **get_tenders_summary**: Resumen de licitaciones guardadas

**ActivaciÃ³n**: AutomÃ¡tica si hay usuario autenticado

#### ğŸ” Tools de BÃºsqueda (5)
**DescripciÃ³n**: BÃºsqueda y filtrado de licitaciones

3. **search_tenders**: BÃºsqueda vectorial semÃ¡ntica (ChromaDB)
4. **find_by_budget**: Filtrado por rango de presupuesto (SQL)
5. **find_by_deadline**: Filtrado por fecha lÃ­mite (SQL)
6. **find_by_cpv**: Filtrado por sector CPV (ChromaDB)
7. **find_by_location**: Filtrado geogrÃ¡fico NUTS (ChromaDB)

**ActivaciÃ³n**: Siempre disponibles

#### ğŸ“„ Tools de InformaciÃ³n (2)
**DescripciÃ³n**: Detalles completos de licitaciones

8. **get_tender_details**: InformaciÃ³n completa desde DB
9. **get_tender_xml**: XML original completo

**ActivaciÃ³n**: Siempre disponibles

#### ğŸ“Š Tools de AnÃ¡lisis (2)
**DescripciÃ³n**: EstadÃ­sticas y comparaciones

10. **get_statistics**: EstadÃ­sticas agregadas
11. **compare_tenders**: ComparaciÃ³n lado a lado (2-5 licitaciones)

**ActivaciÃ³n**: Siempre disponibles

#### ğŸ¯ Tools de Calidad (2 - Opcionales)
**DescripciÃ³n**: Mejora de resultados

12. **grade_documents**: Filtrado inteligente de documentos irrelevantes
13. **verify_fields**: VerificaciÃ³n de campos crÃ­ticos con XML

**ActivaciÃ³n**: `use_grading=True`, `use_verification=True` en User model

#### ğŸŒ Tools de Web (3 - Opcionales)
**DescripciÃ³n**: BÃºsqueda e interacciÃ³n web

14. **web_search**: Google Custom Search API
15. **browse_webpage**: ExtracciÃ³n HTML estÃ¡tica (requests + BeautifulSoup)
16. **browse_interactive**: Navegador con Playwright (JavaScript, clicks, formularios)

**ActivaciÃ³n**:
- `use_web_search=True` + Google API credentials
- `browse_interactive` requiere Playwright instalado

---

## ğŸ”„ Sistema de Review y Mejora

### Flujo Completo del Review Loop

```
1. ITERACIÃ“N INICIAL
   Usuario: "Dame las mejores licitaciones de software"
   â†“
   Agent ejecuta tools â†’ Genera respuesta inicial
   â†“

2. REVIEW (SIEMPRE ejecutado)
   ResponseReviewer analiza:
   - Formato: Â¿Usa ## para cada licitaciÃ³n?
   - Contenido: Â¿Incluye presupuestos, plazos?
   - AnÃ¡lisis: Â¿Justifica por quÃ© son las "mejores"?
   â†“
   Resultado: {
     status: "NEEDS_IMPROVEMENT" / "APPROVED",
     score: 75,
     issues: ["Falta justificaciÃ³n de por quÃ© son mejores"],
     suggestions: ["Agregar anÃ¡lisis de fit con perfil usuario"],
     feedback: "Explica por quÃ© cada licitaciÃ³n es adecuada"
   }
   â†“

3. SEGUNDA ITERACIÃ“N (SIEMPRE ejecutada)
   Prompt mejorado:
   "Tu respuesta inicial: [...]
    Problemas: [...]
    Sugerencias: [...]

    Genera respuesta MEJORADA con acceso a tools"
   â†“
   Agent ejecuta tools nuevamente si necesita â†’ Genera respuesta mejorada
   â†“

4. MERGE Y RETORNO
   - Response final: respuesta mejorada
   - Documents: docs iteraciÃ³n 1 + docs iteraciÃ³n 2
   - Tools used: union de ambas iteraciones
   - Metadata: incluye info de review
```

### Metadata de Review

```python
{
    'review': {
        'review_performed': True,
        'review_status': 'NEEDS_IMPROVEMENT',
        'review_score': 75,
        'review_issues': ['Falta X', 'Falta Y'],
        'review_suggestions': ['Agregar Z'],
        'improvement_applied': True
    }
}
```

---

## ğŸ”„ Flujo de Datos Completo

### Usuario hace pregunta: "Busca licitaciones de IT > 50k con review"

```
1. FRONTEND
   JavaScript â†’ POST /chat/<session_id>/message/

2. DJANGO VIEWS
   ChatMessageCreateView
   â†’ Guarda mensaje usuario
   â†’ Llama ChatAgentService.process_message()

3. CHATAGENTSERVICE - ITERACIÃ“N 1
   â†’ Crea FunctionCallingAgent
   â†’ Ejecuta agent.query()

4. FUNCTIONCALLINGAGENT - ITERACIÃ“N 1
   Paso 1: LLM decide tools
   â†’ "Voy a usar find_by_cpv('IT') y find_by_budget(min=50000)"

   Paso 2: ToolRegistry ejecuta
   â†’ find_by_cpv â†’ 10 licitaciones IT
   â†’ find_by_budget â†’ 8 licitaciones >50k

   Paso 3: LLM genera respuesta inicial
   â†’ "EncontrÃ© 3 licitaciones que cumplen ambos criterios..."

   Retorna: {answer, documents, tools_used, iterations}

5. CHATAGENTSERVICE - REVIEW
   â†’ Crea ResponseReviewer(llm)
   â†’ reviewer.review_response()

6. RESPONSEREVIEWER
   â†’ Llama LLM con prompt de revisiÃ³n
   â†’ Analiza formato, contenido, anÃ¡lisis
   â†’ Retorna: {status, score, issues, suggestions, feedback}

7. CHATAGENTSERVICE - ITERACIÃ“N 2 (SIEMPRE)
   â†’ Construye improvement_prompt
   â†’ Ejecuta agent.query(improvement_prompt)

8. FUNCTIONCALLINGAGENT - ITERACIÃ“N 2
   Paso 1: LLM lee feedback
   â†’ "Necesito agregar anÃ¡lisis de por quÃ© son las mejores"
   â†’ "Voy a usar get_company_info() para contexto"

   Paso 2: Ejecuta get_company_info
   â†’ Perfil de empresa del usuario

   Paso 3: LLM genera respuesta mejorada
   â†’ "BasÃ¡ndome en tu perfil de empresa...
      estas son las mejores porque:
      1. LicitaciÃ³n X - match 95% con tu experiencia..."

   Retorna: {answer mejorado, documents nuevos, tools_used}

9. CHATAGENTSERVICE - MERGE
   â†’ Response final = respuesta mejorada
   â†’ Documents = docs iter1 + docs iter2
   â†’ Tools used = union
   â†’ Metadata incluye review tracking

10. DJANGO VIEWS
    â†’ Guarda ChatMessage con respuesta final
    â†’ Retorna JSON al frontend

11. FRONTEND
    â†’ Renderiza respuesta mejorada
    â†’ Muestra metadata (review score, tools usadas)
```

---

## ğŸ¤– Proveedores LLM

### Ollama (Local)

**ComunicaciÃ³n**:
```python
import ollama

response = ollama.chat(
    model='qwen2.5:7b',
    messages=messages,
    tools=tool_registry.get_ollama_tools()
)
```

**Ventajas**:
- ğŸ†“ Gratis
- ğŸ”’ 100% local (privacidad)
- âš¡ Sin latencia de red

**Desventajas**:
- ğŸ’» Requiere recursos (16GB+ RAM)
- ğŸ¯ Calidad depende del modelo

### OpenAI (Cloud)

**ComunicaciÃ³n**:
```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model='gpt-4o-mini', api_key=api_key)
llm_with_tools = llm.bind_tools(tool_registry.get_openai_tools())
response = llm_with_tools.invoke(messages)
```

**Ventajas**:
- ğŸ¯ Alta calidad
- âš¡ RÃ¡pido
- ğŸ“Š Excelente en consultas complejas

**Desventajas**:
- ğŸ’° Costo por token
- â˜ï¸ Datos en cloud

### Google Gemini (Cloud)

**ComunicaciÃ³n**:
```python
from langchain_google_genai import ChatGoogleGenerativeAI

llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash-exp', api_key=api_key)
llm_with_tools = llm.bind_tools(tool_registry.get_gemini_tools())
response = llm_with_tools.invoke(messages)
```

**Ventajas**:
- ğŸ’° MÃ¡s econÃ³mico que OpenAI
- âš¡ Muy rÃ¡pido
- ğŸ¯ Buena calidad

**Desventajas**:
- ğŸ’° Costo por token
- â˜ï¸ Datos en cloud

---

## ğŸ’¾ Base de Datos

### Modelos Django

#### User (authentication/models.py)
```python
class User(AbstractUser):
    # Basic
    email = EmailField(unique=True)

    # LLM Config
    llm_provider = CharField(max_length=50)  # 'ollama', 'openai', 'google'
    llm_api_key = TextField(blank=True)
    ollama_model = CharField(max_length=100)
    openai_model = CharField(max_length=100)  # Nuevo campo

    # Features
    use_function_calling = BooleanField(default=True)
    use_grading = BooleanField(default=False)
    use_verification = BooleanField(default=False)
    use_web_search = BooleanField(default=False)

    # Google Custom Search (para web_search)
    google_search_api_key = TextField(blank=True)
    google_search_engine_id = CharField(max_length=100, blank=True)

    # Browse settings
    browse_max_chars = IntegerField(default=10000)
    browse_chunk_size = IntegerField(default=1250)
```

#### Tender (tenders/models.py)
```python
class Tender(Model):
    ojs_notice_id = CharField(max_length=255, unique=True)
    title = TextField()
    description = TextField(blank=True)
    buyer_name = CharField(max_length=500)
    budget_amount = DecimalField(max_digits=15, decimal_places=2, null=True)
    currency = CharField(max_length=3, null=True)
    tender_deadline_date = DateField(null=True)
    cpv_codes = JSONField(default=list)
    nuts_regions = JSONField(default=list)
    source_path = CharField(max_length=500, blank=True)
```

#### ChatMessage (chat/models.py)
```python
class ChatMessage(Model):
    session = ForeignKey(ChatSession, on_delete=CASCADE)
    role = CharField(max_length=20)  # 'user', 'assistant'
    content = TextField()
    timestamp = DateTimeField(auto_now_add=True)
    metadata = JSONField(default=dict)  # Incluye review tracking
```

### ChromaDB

**ColecciÃ³n**: `eforms_chunks`
**Documentos**: 235+ chunks

**Metadata por documento**:
```python
{
    'ojs_notice_id': '00668461-2025',
    'section': 'object_description',
    'title': 'Desarrollo de software',
    'buyer_name': 'Ministerio',
    'cpv_codes': ['72000000'],
    'nuts_regions': ['ES300'],
    'budget_amount': 961200.0,
    'budget_eur': '961200.0',  # String para filtros
    'tender_deadline_date': '2025-09-15'
}
```

---

## ğŸ“Š MÃ©tricas de Rendimiento

### Latencia con Review Loop

| OperaciÃ³n | Ollama | OpenAI | Gemini |
|-----------|--------|--------|--------|
| **IteraciÃ³n 1** | 500-1000ms | 800-1500ms | 600-1200ms |
| **Review** | 200-400ms | 300-600ms | 200-500ms |
| **IteraciÃ³n 2** | 500-1000ms | 800-1500ms | 600-1200ms |
| **Total** | 1.2-2.4s | 1.9-3.6s | 1.4-2.9s |

### Consumo de Recursos

| Proveedor | RAM | CPU | Disco | Red |
|-----------|-----|-----|-------|-----|
| **Ollama** | 8-16GB | Alto | 5-10GB | No |
| **OpenAI** | < 500MB | Bajo | MÃ­nimo | SÃ­ |
| **Gemini** | < 500MB | Bajo | MÃ­nimo | SÃ­ |

---

## ğŸ”— Referencias

- **CÃ³digo fuente**: `agent_ia_core/`, `chat/`
- **Tools**: [TOOLS_REFERENCE.md](TOOLS_REFERENCE.md)
- **Flujo completo**: [FLUJO_EJECUCION_CHAT.md](FLUJO_EJECUCION_CHAT.md)
- **ConfiguraciÃ³n**: [CONFIGURACION_AGENTE.md](CONFIGURACION_AGENTE.md)
- **Changelog**: [CHANGELOG.md](CHANGELOG.md)

---

**VersiÃ³n**: 3.7.0
**Ãšltima actualizaciÃ³n**: 2025-01-19
**Features destacadas**: Review Loop automÃ¡tico, Playwright Interactive Browser, 16 tools

**ğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)**

**Co-Authored-By: Claude <noreply@anthropic.com>**
